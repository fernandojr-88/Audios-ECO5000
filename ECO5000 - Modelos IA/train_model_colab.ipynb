{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Leak Detection Model Training\n",
        "\n",
        "This notebook trains a model to classify audio files as:\n",
        "- Leak-Metal\n",
        "- Leak-NonMetal\n",
        "- NoLeak-Metal\n",
        "- NoLeak-NonMetal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment\n",
        "\n",
        "First, install required packages and mount Google Drive (if your data is stored there).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (if your project is in Drive)\n",
        "# Uncomment the following lines if needed:\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# If uploading files directly to Colab, use:\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing\n",
        "\n",
        "Define paths and load audio files. Adjust the base path according to your setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define base path\n",
        "# Adjust this path based on where your data is located\n",
        "# If in Drive: BASE_PATH = '/content/drive/MyDrive/ECO5000 - Modelos IA'\n",
        "# If uploaded: BASE_PATH = '/content'\n",
        "# If in repository: BASE_PATH = '/content'\n",
        "\n",
        "BASE_PATH = '/content'  # Change this as needed\n",
        "AUDIO_DIR = os.path.join(BASE_PATH, 'Audios para Treinamento')\n",
        "\n",
        "# Verify directory exists\n",
        "if os.path.exists(AUDIO_DIR):\n",
        "    print(f\"Audio directory found: {AUDIO_DIR}\")\n",
        "    print(\"\\nClass directories:\")\n",
        "    for class_dir in os.listdir(AUDIO_DIR):\n",
        "        class_path = os.path.join(AUDIO_DIR, class_dir)\n",
        "        if os.path.isdir(class_path):\n",
        "            num_files = len([f for f in os.listdir(class_path) if f.endswith('.wav')])\n",
        "            print(f\"  {class_dir}: {num_files} files\")\n",
        "else:\n",
        "    print(f\"Warning: Audio directory not found at {AUDIO_DIR}\")\n",
        "    print(\"Please adjust BASE_PATH or upload your data.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_features(file_path, n_mfcc=13, n_mels=128, n_fft=2048, hop_length=512):\n",
        "    \"\"\"\n",
        "    Extract audio features from a WAV file.\n",
        "    Returns MFCCs, Mel spectrogram, and chroma features.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio file\n",
        "        y, sr = librosa.load(file_path, sr=None)\n",
        "        \n",
        "        # Extract MFCCs\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "        \n",
        "        # Extract Mel spectrogram\n",
        "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, \n",
        "                                                   n_fft=n_fft, hop_length=hop_length)\n",
        "        mel_spec_mean = np.mean(mel_spec.T, axis=0)\n",
        "        \n",
        "        # Extract Chroma features\n",
        "        chroma = librosa.feature.chroma(y=y, sr=sr)\n",
        "        chroma_mean = np.mean(chroma.T, axis=0)\n",
        "        \n",
        "        # Combine features\n",
        "        features = np.concatenate([mfccs_mean, mel_spec_mean, chroma_mean])\n",
        "        \n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"Feature extraction function defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_dataset(audio_dir):\n",
        "    \"\"\"\n",
        "    Load all audio files and extract features.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    labels = []\n",
        "    file_paths = []\n",
        "    \n",
        "    class_dirs = [d for d in os.listdir(audio_dir) if os.path.isdir(os.path.join(audio_dir, d))]\n",
        "    \n",
        "    for class_name in class_dirs:\n",
        "        class_path = os.path.join(audio_dir, class_name)\n",
        "        audio_files = [f for f in os.listdir(class_path) if f.endswith('.wav')]\n",
        "        \n",
        "        print(f\"\\nProcessing {class_name}... ({len(audio_files)} files)\")\n",
        "        \n",
        "        for audio_file in tqdm(audio_files, desc=f\"  {class_name}\"):\n",
        "            file_path = os.path.join(class_path, audio_file)\n",
        "            feature = extract_features(file_path)\n",
        "            \n",
        "            if feature is not None:\n",
        "                features.append(feature)\n",
        "                labels.append(class_name)\n",
        "                file_paths.append(file_path)\n",
        "    \n",
        "    return np.array(features), np.array(labels), file_paths\n",
        "\n",
        "# Load the dataset\n",
        "print(\"Loading dataset...\")\n",
        "X, y, paths = load_dataset(AUDIO_DIR)\n",
        "\n",
        "print(f\"\\nDataset loaded:\")\n",
        "print(f\"  Features shape: {X.shape}\")\n",
        "print(f\"  Labels shape: {y.shape}\")\n",
        "print(f\"  Classes: {np.unique(y)}\")\n",
        "print(f\"  Class distribution:\")\n",
        "for class_name, count in zip(*np.unique(y, return_counts=True)):\n",
        "    print(f\"    {class_name}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing and Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "print(f\"Label mapping:\")\n",
        "for i, class_name in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {i}: {class_name}\")\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"\\nNumber of classes: {num_classes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Further split training set into train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "print(f\"Dataset split:\")\n",
        "print(f\"  Training: {X_train.shape[0]} samples\")\n",
        "print(f\"  Validation: {X_val.shape[0]} samples\")\n",
        "print(f\"  Test: {X_test.shape[0]} samples\")\n",
        "print(f\"  Feature dimension: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Features normalized.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build and Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(input_dim, num_classes):\n",
        "    \"\"\"\n",
        "    Create a neural network model for audio classification.\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create model\n",
        "model = create_model(X_train_scaled.shape[1], num_classes)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'best_model.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=0.00001\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_scaled, verbose=0)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes, \n",
        "                          target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=label_encoder.classes_,\n",
        "            yticklabels=label_encoder.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Accuracy\n",
        "ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_title('Model Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Loss\n",
        "ax2.plot(history.history['loss'], label='Train Loss')\n",
        "ax2.plot(history.history['val_loss'], label='Val Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_title('Model Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save Model\n",
        "\n",
        "Save the trained model for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "model.save('audio_leak_classifier.h5')\n",
        "print(\"Model saved as 'audio_leak_classifier.h5'\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

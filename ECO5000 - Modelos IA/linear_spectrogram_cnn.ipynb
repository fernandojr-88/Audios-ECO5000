{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 5: Using High-Resolution Linear Spectrograms\n",
        "\n",
        "In our previous experiments, we used Mel spectrograms, which are designed to mimic the human ear's response to frequency. This is a standard and effective technique, but it's a form of feature compressionâ€”it smooths over fine frequency details.\n",
        "\n",
        "This notebook explores a different hypothesis: **what if the key distinguishing features between a leak and other sounds are contained in those very fine-grained frequency details?**\n",
        "\n",
        "To test this, we will replace the Mel spectrogram with a standard **linear-frequency STFT spectrogram**. Crucially, we will also increase the FFT resolution (`n_fft`) to provide the model with a much more detailed view of the frequency spectrum.\n",
        "\n",
        "Our workflow will be:\n",
        "1.  Adapt our processing pipeline to generate high-resolution, linear-frequency spectrograms.\n",
        "2.  Use our best augmentation strategy (randomized augmentation on the training set).\n",
        "3.  Train the same binary CNN architecture on this new data representation.\n",
        "4.  Evaluate its performance and compare it to our best Mel-spectrogram-based model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tensorflow scikit-learn librosa numpy pandas matplotlib seaborn tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preparation with High-Resolution Linear Spectrograms\n",
        "\n",
        "The core change is in this section. We define a larger `N_FFT` to increase our frequency resolution. Then, our audio processing function will use `librosa.stft` to create a linear spectrogram and `librosa.amplitude_to_db` to convert it to a decibel scale. All the augmentation logic will remain the same.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Parameters ---\n",
        "BASE_AUDIO_PATH = 'Audios para Treinamento/'\n",
        "FIXED_DURATION_S = 10\n",
        "SAMPLE_RATE = 22050\n",
        "FIXED_LENGTH = SAMPLE_RATE * FIXED_DURATION_S\n",
        "\n",
        "# --- New STFT Parameters for Higher Resolution ---\n",
        "N_FFT = 4096  # Increased from default 2048\n",
        "HOP_LENGTH = 512 # Same as default\n",
        "\n",
        "# --- Augmentation Functions (same as before) ---\n",
        "def add_noise(audio, noise_factor=0.005):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    return audio + noise_factor * noise\n",
        "\n",
        "def time_stretch(audio, stretch_rate=0.8):\n",
        "    return librosa.effects.time_stretch(y=audio, rate=stretch_rate)\n",
        "\n",
        "def pitch_shift(audio, sample_rate, n_steps=4):\n",
        "    return librosa.effects.pitch_shift(y=audio, sr=sample_rate, n_steps=n_steps)\n",
        "\n",
        "def time_shift(audio, shift_max_percent=0.2):\n",
        "    shift = int(len(audio) * shift_max_percent * random.uniform(-1, 1))\n",
        "    return np.roll(audio, shift)\n",
        "\n",
        "# --- Get all file paths and their binary labels ---\n",
        "classes = os.listdir(BASE_AUDIO_PATH)\n",
        "all_files, all_binary_labels = [], []\n",
        "for label in classes:\n",
        "    class_path = os.path.join(BASE_AUDIO_PATH, label)\n",
        "    files = [os.path.join(class_path, f) for f in os.listdir(class_path) if f.endswith('.wav')]\n",
        "    all_files.extend(files)\n",
        "    binary_label = 'NoLeak' if label.startswith('NoLeak') else 'Leak'\n",
        "    all_binary_labels.extend([binary_label] * len(files))\n",
        "\n",
        "# --- Split file paths into training and validation sets ---\n",
        "train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "    all_files, all_binary_labels, test_size=0.2, random_state=42, stratify=all_binary_labels\n",
        ")\n",
        "\n",
        "print(f\"Training files: {len(train_files)}\")\n",
        "print(f\"Validation files: {len(val_files)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Process Audio with Linear Spectrograms and Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This new function creates a linear-frequency spectrogram\n",
        "def audio_to_linear_spectrogram(audio, sample_rate):\n",
        "    # Pad or truncate\n",
        "    if len(audio) < FIXED_LENGTH:\n",
        "        audio = np.pad(audio, (0, FIXED_LENGTH - len(audio)), 'constant')\n",
        "    else:\n",
        "        audio = audio[:FIXED_LENGTH]\n",
        "    \n",
        "    # Create STFT\n",
        "    stft = librosa.stft(audio, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
        "    \n",
        "    # Convert amplitude to dB\n",
        "    spectrogram_db = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
        "    return spectrogram_db\n",
        "\n",
        "# --- Process training and validation sets ---\n",
        "X_train_lin, y_train_lin = [], []\n",
        "X_val_lin, y_val_lin = [], []\n",
        "AUGMENTATIONS_PER_FILE = 4\n",
        "\n",
        "augmentation_choices = [add_noise, time_stretch, pitch_shift, time_shift]\n",
        "\n",
        "print(\"Processing and augmenting training data with linear spectrograms...\")\n",
        "for file, label in tqdm(zip(train_files, train_labels), total=len(train_files)):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file, sr=SAMPLE_RATE)\n",
        "\n",
        "        # 1. Add the original audio\n",
        "        X_train_lin.append(audio_to_linear_spectrogram(audio, sr))\n",
        "        y_train_lin.append(label)\n",
        "\n",
        "        # 2. Add augmented versions\n",
        "        for _ in range(AUGMENTATIONS_PER_FILE):\n",
        "            aug_func = random.choice(augmentation_choices)\n",
        "            if aug_func == pitch_shift:\n",
        "                augmented_audio = aug_func(audio, sample_rate=sr)\n",
        "            else:\n",
        "                augmented_audio = aug_func(audio)\n",
        "            \n",
        "            X_train_lin.append(audio_to_linear_spectrogram(augmented_audio, sr))\n",
        "            y_train_lin.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during augmentation for {file}: {e}\")\n",
        "\n",
        "print(\"\\nProcessing validation data...\")\n",
        "for file, label in tqdm(zip(val_files, val_labels), total=len(val_files)):\n",
        "    try:\n",
        "        audio, sr = librosa.load(file, sr=SAMPLE_RATE)\n",
        "        spec = audio_to_linear_spectrogram(audio, sr)\n",
        "        X_val_lin.append(spec)\n",
        "        y_val_lin.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing validation file {file}: {e}\")\n",
        "\n",
        "# --- Prepare data for the model ---\n",
        "X_train_lin = np.array(X_train_lin)[..., np.newaxis]\n",
        "y_train_lin = np.array(y_train_lin)\n",
        "\n",
        "X_val_lin = np.array(X_val_lin)[..., np.newaxis]\n",
        "y_val_lin = np.array(y_val_lin)\n",
        "\n",
        "# Encode labels\n",
        "lin_label_encoder = LabelEncoder()\n",
        "y_train_lin_enc = lin_label_encoder.fit_transform(y_train_lin)\n",
        "y_val_lin_enc = lin_label_encoder.transform(y_val_lin)\n",
        "\n",
        "print(f\"\\nNew training set size: {X_train_lin.shape[0]} samples\")\n",
        "print(f\"Spectrogram shape: {X_train_lin.shape[1:]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build, Train, and Evaluate the Model\n",
        "\n",
        "The architecture is identical to our previous binary model. The only difference is the input shape, which is now much taller due to the higher frequency resolution. We will train and evaluate it in the same way.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lin_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=X_train_lin.shape[1:]),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "lin_model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "lin_model.summary()\n",
        "\n",
        "EPOCHS_LIN = 75\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "lin_history = lin_model.fit(X_train_lin, y_train_lin_enc,\n",
        "                            epochs=EPOCHS_LIN,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            validation_data=(X_val_lin, y_val_lin_enc),\n",
        "                            verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Final Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting training history\n",
        "pd.DataFrame(lin_history.history).plot(figsize=(12, 6))\n",
        "plt.grid(True)\n",
        "plt.gca().set_ylim(0, 1)\n",
        "plt.title('Linear Spectrogram Model Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Metric')\n",
        "plt.show()\n",
        "\n",
        "# Make predictions\n",
        "y_pred_probs_lin = lin_model.predict(X_val_lin)\n",
        "y_pred_lin = (y_pred_probs_lin > 0.5).astype(\"int32\").reshape(-1)\n",
        "\n",
        "# Generate and print the classification report\n",
        "print(\"\\\\nLinear Spectrogram Model Classification Report:\\\\n\")\n",
        "print(classification_report(y_val_lin_enc, y_pred_lin, target_names=lin_label_encoder.classes_))\n",
        "\n",
        "# Generate and plot the confusion matrix\n",
        "conf_matrix_lin = confusion_matrix(y_val_lin_enc, y_pred_lin)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix_lin, annot=True, fmt='d',\n",
        "            xticklabels=lin_label_encoder.classes_,\n",
        "            yticklabels=lin_label_encoder.classes_,\n",
        "            cmap='Blues')\n",
        "plt.title('Linear Spectrogram Model Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
